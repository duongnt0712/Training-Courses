{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d378618",
   "metadata": {},
   "source": [
    "# Pre-requisites\n",
    "- WSL\n",
    "- Miniconda3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b7962e",
   "metadata": {},
   "source": [
    "# Setup environment\n",
    "- Create conda env `conda create langchain python=3.11`\n",
    "- Set the \"langchain\" env that has been just created as the running env in VS code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b1c37f",
   "metadata": {},
   "source": [
    "Install langchain and openai package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f5a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22f15eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf chroma_bonbon_azure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a7f087",
   "metadata": {},
   "source": [
    "# Init variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735b86f7",
   "metadata": {},
   "source": [
    "You need to set value of `OPEN_API_KEY` that you get from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d055f5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f4a78d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_type = os.getenv(\"EMBED_OPENAI_API_TYPE\")\n",
    "embed_openai_api_key = os.getenv(\"EMBED_OPENAI_API_KEY\")\n",
    "embed_openai_api_version = os.getenv(\"EMBED_OPENAI_API_VERSION\")\n",
    "embed_azure_openai_endpoint = os.getenv(\"EMBED_AZURE_OPENAI_ENDPOINT\")\n",
    "embed_model = os.getenv(\"EMBED_MODEL\")\n",
    "embed_deployment = os.getenv(\"EMBED_DEPLOYMENT\")\n",
    "\n",
    "persist_directory = \"chroma_bonbon_azure\"\n",
    "pdf_path = \"BonBon_FAQ.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75fb66e",
   "metadata": {},
   "source": [
    "# Overviews\n",
    "\n",
    "The BonBon FAQ.pdf file contains frequently asked questions and answers for customer support scenario. The topics are around IT related issue troubleshooting such as networking, software, hardware. You are requested to provide a solution to build a chat bot capable of answering the user questions with LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45d8dd7",
   "metadata": {},
   "source": [
    "## Assignment 1: Document Indexing (mandatory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ae6ac3",
   "metadata": {},
   "source": [
    "- The content of BonBon FAQ.pdf should be indexed to the local Chroma vector DB from where the chatbot can lookup the appropriate information to answer questions.\n",
    "- Should use some embedding model such as Azure Open AI text-embedding-3-small to create vectors, feel free to use any other open source embedding model if it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad3d4ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load_and_split()\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    doc.metadata[\"source\"] = \"BonBon_FAQ.pdf\"\n",
    "    doc.metadata[\"page\"] = i + 1\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embedding_model = AzureOpenAIEmbeddings(\n",
    "    deployment=embed_deployment,  \n",
    "    model=embed_model,\n",
    ")\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd818ec",
   "metadata": {},
   "source": [
    "## Assignment 2: Building Chatbot (mandatory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58fce4e",
   "metadata": {},
   "source": [
    "- You are requested to build a chatbot solution for customer support scenario using Conversational ReAct agent supported in LangChain\n",
    "- The chatbot is able to support user to answer FAQs in the sample BonBon FAQ.pdf file.\n",
    "- The chatbot should use Azure Open AI GPT-4o LLM as the reasoning engine.\n",
    "- The chatbot should be context aware, meaning that it should be able to chat with users in the conversation manner.\n",
    "- The agent is equipped the following tools:\n",
    "  - Internet Search: Help the chatbot automatically find out more about something using Duck Duck Go internet search\n",
    "  - Knowledge Base Search: Help the chatbot to lookup information in the private knowledge base\n",
    "- In case user asks for information related to topics in the BonBon FAQ.pdf file such as internet connection, printer, malware issues the chatbot must use the private knowledge base, otherwise it should search on the internet to answer the question.\n",
    "- In the answer of chatbot, it should mention the source file and the page that the answer belongs to, for example the answer should mention \"BonBon FQA.pdf (page 2)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5214ff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_qa_answer(docs):\n",
    "  result = []\n",
    "  for doc in docs:\n",
    "    content = doc.page_content.strip()\n",
    "    source = doc.metadata.get(\"source\", \"Unknown\")\n",
    "    page = doc.metadata.get(\"page\", \"?\")\n",
    "    result.append(f\"{content}\\n(Source: {source} - page {page})\")\n",
    "  return \"\\n\\n\".join(result)\n",
    "\n",
    "def knowledge_search_tool(query: str) -> str:\n",
    "  results = vectordb.similarity_search(query, k=2)\n",
    "  return format_qa_answer(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dedbd10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_openai_api_key = os.getenv(\"CHAT_OPENAI_API_KEY\")\n",
    "chat_openai_api_version = os.getenv(\"CHAT_OPENAI_API_VERSION\")\n",
    "chat_azure_openai_endpoint = os.getenv(\"CHAT_AZURE_OPENAI_ENDPOINT\")\n",
    "chat_model = os.getenv(\"CHAT_MODEL\")\n",
    "chat_deployment = os.getenv(\"CHAT_DEPLOYMENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a8b594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "  azure_deployment=chat_deployment,\n",
    "  model=chat_model,\n",
    "  api_version=chat_openai_api_version,\n",
    "  azure_endpoint=chat_azure_openai_endpoint,\n",
    "  openai_api_key=chat_openai_api_key\n",
    ")\n",
    "\n",
    "embedding_model = AzureOpenAIEmbeddings(\n",
    "  deployment=embed_deployment,  \n",
    "  model=embed_model\n",
    ")\n",
    "\n",
    "vectordb = Chroma(\n",
    "  persist_directory=persist_directory,\n",
    "  embedding_function=embedding_model\n",
    ")\n",
    "\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "tools = [\n",
    "  Tool(\n",
    "    name=\"KnowledgeBaseSearch\",\n",
    "    func=knowledge_search_tool,\n",
    "    description=\"Useful for answering questions about internal systems like internet connection, printer, malware issues based on BonBon_FAQ.pdf. Must include source and page in final answer.\"\n",
    "  ),\n",
    "  Tool(\n",
    "    name=\"InternetSearch\",\n",
    "    func=search_tool.run,\n",
    "    description=\"Useful for answering general questions or anything not found in BonBon_FAQ.pdf\"\n",
    "  ),\n",
    "]\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "agent = initialize_agent(\n",
    "  tools=tools,\n",
    "  llm=llm,\n",
    "  agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "  verbose=True,\n",
    "  memory=memory,\n",
    "  handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95a1eb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"KnowledgeBaseSearch\",\n",
      "    \"action_input\": \"resetting password\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mthe priority of\n",
      "incidents so that the Service Desk team can effectively allocate resources \n",
      "and provide timely\n",
      "support.\n",
      "Frequently Asked Questions:\n",
      " Q How do I reset my password?\n",
      "A Go to “Where to Reset my Password for which applicationˮ web page @ \n",
      "the following link –\n",
      "www.anycorp.intranet.passwordreset/com. There you will be able to select \n",
      "application for which you\n",
      "need to reset your password and will receive further instructions\n",
      "(Source: BonBon_FAQ.pdf - page 4)\n",
      "\n",
      "the priority of\n",
      "incidents so that the Service Desk team can effectively allocate resources \n",
      "and provide timely\n",
      "support.\n",
      "Frequently Asked Questions:\n",
      " Q How do I reset my password?\n",
      "A Go to “Where to Reset my Password for which applicationˮ web page @ \n",
      "the following link –\n",
      "www.anycorp.intranet.passwordreset/com. There you will be able to select \n",
      "application for which you\n",
      "need to reset your password and will receive further instructions\n",
      "(Source: BonBon_FAQ.pdf - page 4)\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"To reset your password, go to the 'Where to Reset my Password for which application' web page at the following link: www.anycorp.intranet.passwordreset/com. There, you can select the application for which you need to reset your password and receive further instructions. (Source: BonBon_FAQ.pdf - page 4)\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"To reset your password, go to the 'Where to Reset my Password for which application' web page at the following link: www.anycorp.intranet.passwordreset/com. There, you can select the application for which you need to reset your password and receive further instructions. (Source: BonBon_FAQ.pdf - page 4)\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"I want to reset my password, how to do it?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5e5b89",
   "metadata": {},
   "source": [
    "## [SKIP] Assignment 3: Build a new assistant based on BonBon source code (optional)\n",
    "The objective\n",
    "- Run the code and index the sample BonBon FAQ.pdf file to Azure Cognitive Search\n",
    "- Explore the code and implement a new assistant that has the same behavior as above\n",
    "- Explore other features such as RBACs, features on admin portal\n",
    "\n",
    "Please contact the training team in case you need to get the source code of BonBon."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
